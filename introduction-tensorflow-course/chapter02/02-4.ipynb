{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600571980274",
   "display_name": "Python 3.7.7 64-bit ('tf': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_images  = training_images / 255.0\n",
    "# test_images = test_images / 255.0\n",
    "training_images_reshape = tf.reshape(training_images,(-1,(28*28)))\n",
    "test_images_reshape = tf.reshape(test_images,(-1,(28*28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/5\n1875/1875 [==============================] - 3s 2ms/step - loss: 2.9323 - accuracy: 0.7140\nEpoch 2/5\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.6116 - accuracy: 0.7851\nEpoch 3/5\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.5548 - accuracy: 0.8095\nEpoch 4/5\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.5235 - accuracy: 0.8194\nEpoch 5/5\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.5087 - accuracy: 0.8267\n313/313 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.8277\n[1.2065609e-33 0.0000000e+00 1.8416937e-35 6.5440453e-24 0.0000000e+00\n 7.4037802e-03 1.3941540e-30 3.8797900e-03 2.3881689e-14 9.8871636e-01]\n9\n"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "visible = Input(shape=(28*28,))\n",
    "input_flatten = Flatten()(visible) # 變成一維\n",
    "hidden = Dense(128, activation=tf.nn.relu)(input_flatten) # 第一層神經元\n",
    "output = Dense(10, activation=tf.nn.softmax)(hidden)\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "\n",
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images_reshape, training_labels, epochs=5)\n",
    "model.evaluate(test_images_reshape, test_labels)\n",
    "classifications = model.predict(test_images_reshape)\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 4.7018 - accuracy: 0.7581\nEpoch 2/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.5210 - accuracy: 0.8214\nEpoch 3/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.4949 - accuracy: 0.8289\nEpoch 4/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.4869 - accuracy: 0.8310\nEpoch 5/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.4797 - accuracy: 0.8374\n313/313 [==============================] - 1s 2ms/step - loss: 0.4787 - accuracy: 0.8392\n[2.0998893e-21 3.8399415e-14 3.8109487e-20 5.2610781e-17 3.0065822e-17\n 8.9101149e-03 8.1024615e-16 2.7006658e-02 2.7485911e-12 9.6408325e-01]\n9\n"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "visible = Input(shape=(28*28,))\n",
    "input_flatten = Flatten()(visible) # 變成一維\n",
    "hidden = Dense(512, activation=tf.nn.relu)(input_flatten) # 第一層神經元\n",
    "output = Dense(10, activation=tf.nn.softmax)(hidden)\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "\n",
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images_reshape, training_labels, epochs=5)\n",
    "model.evaluate(test_images_reshape, test_labels)\n",
    "classifications = model.predict(test_images_reshape)\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "source": [
    "在損失函數方面和準確度方面沒有正規化後的數據好，因此正規化能夠提升整個模型訓練的準確度"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}